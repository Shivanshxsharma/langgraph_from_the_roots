{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "750a6573",
   "metadata": {},
   "source": [
    "Iterative workflow example, Tweet generation by multiple evaultion and generation cycle for best output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0646b802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"api key here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3b2edf63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict,Literal,Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "727f12e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "class State_Schema(TypedDict):\n",
    "    user_input: str\n",
    "    generated_tweet: str\n",
    "    feedback:str\n",
    "    evaluation: Literal[\"approved\", \"needs_improvement\"]\n",
    "    iteration: Annotated[int, operator.add]\n",
    "    max_iterations: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "077ff8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7e752985",
   "metadata": {},
   "outputs": [],
   "source": [
    "## node fucntions\n",
    "\n",
    "def generate_tweet(state: State_Schema) -> State_Schema:\n",
    "    prompt = [\n",
    "        SystemMessage(\"You are a social media expert specialized in crafting engaging tweets.\"),\n",
    "        HumanMessage(f\"\"\"Create a very basic and simple  single  tweet which is not that great in terms of clarity and thinking  based on the following input: {state[\"user_input\"]}.\"\"\")\n",
    "    ]\n",
    "    response=llm.invoke(prompt).content\n",
    "    return {\"generated_tweet\": response}\n",
    "\n",
    "\n",
    "class evaluation_output(BaseModel):\n",
    "    evaluation: Literal[\"approved\", \"needs_improvement\"]\n",
    "    feedback: str = Field( description=\"Detailed feedback on the tweet.\")\n",
    "\n",
    "\n",
    "def evaluator(state: State_Schema) -> State_Schema:\n",
    "    prompt = [\n",
    "        SystemMessage(\"You are a meticulous tweet evaluator.\"),\n",
    "        HumanMessage(f\"\"\"Evaluate the following tweet: {state[\"generated_tweet\"]}.\n",
    "        If it meets high standards of engagement and clarity, respond with \"approved\". be critical and provide specific feedback for improvement.\n",
    "        Otherwise, if the tweet doesn't meet the standards, respond with \"needs_improvement\"   and generate feedback.\"\"\")\n",
    "    ]\n",
    "    response=llm.with_structured_output(evaluation_output).invoke(prompt)\n",
    "    return {\"evaluation\": response.evaluation, \"feedback\": response.feedback, \"iteration\":state[\"iteration\"]+1}\n",
    "\n",
    "\n",
    "terminate=lambda state: state\n",
    "\n",
    "def check_evaluation(state: State_Schema)->Literal[\"terminate\",\"optimizer\"]:\n",
    "    if state[\"evaluation\"] == \"approved\" or state[\"iteration\"] >= state[\"max_iterations\"]:\n",
    "        return \"terminate\"\n",
    "    else:\n",
    "        return \"optimizer\"\n",
    "    \n",
    "def optimizer(state: State_Schema) -> State_Schema:\n",
    "    prompt = [\n",
    "        SystemMessage(\"You are a skilled tweet optimizer.\"),\n",
    "        HumanMessage(f\"\"\"Optimize the following tweet based on this feedback: {state[\"feedback\"]}.\n",
    "        Original Tweet: {state[\"generated_tweet\"]}.\"\"\")\n",
    "    ]\n",
    "    response=llm.invoke(prompt).content\n",
    "    return {\"generated_tweet\": response}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "37a09a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2217fb57250>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph=StateGraph(State_Schema)\n",
    "graph.add_node(\"generate_tweet\", generate_tweet)\n",
    "graph.add_node(\"evaluator\", evaluator)\n",
    "graph.add_node(\"optimizer\", optimizer)\n",
    "graph.add_node(\"terminate\", terminate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "36f98e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2217fb57250>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_edge(START, \"generate_tweet\")\n",
    "graph.add_edge(\"generate_tweet\", \"evaluator\")\n",
    "graph.add_conditional_edges(\"evaluator\", check_evaluation)\n",
    "graph.add_edge(\"terminate\", END)\n",
    "graph.add_edge(\"optimizer\", \"evaluator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b23b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "workFlow=graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "de76a803",
   "metadata": {},
   "outputs": [
    {
     "ename": "ChatGoogleGenerativeAIError",
     "evalue": "Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 15.814552919s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '15s'}]}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langgraph\\myenv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:3040\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   3039\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3040\u001b[39m     response: GenerateContentResponse = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3041\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3042\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3043\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langgraph\\myenv\\Lib\\site-packages\\google\\genai\\models.py:5203\u001b[39m, in \u001b[36mModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5202\u001b[39m i += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m5203\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparsed_config\u001b[49m\n\u001b[32m   5205\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5207\u001b[39m function_map = _extra_utils.get_function_map(parsed_config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langgraph\\myenv\\Lib\\site-packages\\google\\genai\\models.py:3985\u001b[39m, in \u001b[36mModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   3983\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m3985\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3986\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   3987\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   3990\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3991\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langgraph\\myenv\\Lib\\site-packages\\google\\genai\\_api_client.py:1388\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1385\u001b[39m http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1386\u001b[39m     http_method, path, request_dict, http_options\n\u001b[32m   1387\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1388\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1389\u001b[39m response_body = (\n\u001b[32m   1390\u001b[39m     response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1391\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langgraph\\myenv\\Lib\\site-packages\\google\\genai\\_api_client.py:1222\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1221\u001b[39m     retry = tenacity.Retrying(**retry_kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langgraph\\myenv\\Lib\\site-packages\\tenacity\\__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langgraph\\myenv\\Lib\\site-packages\\tenacity\\__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langgraph\\myenv\\Lib\\site-packages\\tenacity\\__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langgraph\\myenv\\Lib\\site-packages\\tenacity\\__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langgraph\\myenv\\Lib\\site-packages\\tenacity\\__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langgraph\\myenv\\Lib\\site-packages\\google\\genai\\_api_client.py:1201\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1194\u001b[39m response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m   1195\u001b[39m     method=http_request.method,\n\u001b[32m   1196\u001b[39m     url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1199\u001b[39m     timeout=http_request.timeout,\n\u001b[32m   1200\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1201\u001b[39m \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1203\u001b[39m     response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1204\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langgraph\\myenv\\Lib\\site-packages\\google\\genai\\errors.py:121\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    119\u001b[39m   response_json = response.body_segments[\u001b[32m0\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langgraph\\myenv\\Lib\\site-packages\\google\\genai\\errors.py:146\u001b[39m, in \u001b[36mAPIError.raise_error\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n",
      "\u001b[31mClientError\u001b[39m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 15.814552919s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '15s'}]}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mChatGoogleGenerativeAIError\u001b[39m               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[165]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m result=\u001b[43mworkFlow\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43muser_input\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgive a review of animal movie\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_iterations\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43miteration\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langgraph\\myenv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3068\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3065\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3066\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3068\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3069\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langgraph\\myenv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2643\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2641\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2642\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2643\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2644\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2653\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langgraph\\myenv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langgraph\\myenv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langgraph\\myenv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langgraph\\myenv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[161]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mgenerate_tweet\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_tweet\u001b[39m(state: State_Schema) -> State_Schema:\n\u001b[32m      4\u001b[39m     prompt = [\n\u001b[32m      5\u001b[39m         SystemMessage(\u001b[33m\"\u001b[39m\u001b[33mYou are a social media expert specialized in crafting engaging tweets.\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      6\u001b[39m         HumanMessage(\u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mCreate a very basic and simple  single  tweet which is not that great in terms of clarity and thinking  based on the following input: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate[\u001b[33m\"\u001b[39m\u001b[33muser_input\u001b[39m\u001b[33m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\"\"\u001b[39m)\n\u001b[32m      7\u001b[39m     ]\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     response=\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m.content\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mgenerated_tweet\u001b[39m\u001b[33m\"\u001b[39m: response}\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langgraph\\myenv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:2529\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   2526\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2527\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m2529\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langgraph\\myenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langgraph\\myenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langgraph\\myenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langgraph\\myenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langgraph\\myenv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:3044\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   3040\u001b[39m     response: GenerateContentResponse = \u001b[38;5;28mself\u001b[39m.client.models.generate_content(\n\u001b[32m   3041\u001b[39m         **request,\n\u001b[32m   3042\u001b[39m     )\n\u001b[32m   3043\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m3044\u001b[39m     \u001b[43m_handle_client_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3046\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\langgraph\\myenv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:145\u001b[39m, in \u001b[36m_handle_client_error\u001b[39m\u001b[34m(e, request)\u001b[39m\n\u001b[32m    143\u001b[39m model_name = request.get(\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33munknown\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    144\u001b[39m msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError calling model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me.status\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mChatGoogleGenerativeAIError\u001b[39m: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 15.814552919s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '15s'}]}}",
      "During task with name 'generate_tweet' and id '8306cf49-c26d-bdc0-6ecd-8b656b27d835'"
     ]
    }
   ],
   "source": [
    "result=workFlow.invoke({'user_input':\"give a review of animal movie\",\"max_iterations\":3,\"iteration\":0})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "5c2a263b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(workFlow.get_graph().draw_mermaid_png())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
